{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A\n",
    "1. ALS都有哪些应用场景: ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵, 因此，主要有两部分 1） 评分预测分析，用户对商品合适程度,喜好程度.用户和商品就组成了一个矩阵,只要用户点击了商品,就对这个商品有个评分了,而有的却没有点击,它是空白的,我们要做的就是填充这些空白,在空白处根据之前的权重预测一个评分。 2） topN 归类分析，和rank 类似，但主要是为了实现最主要的 top N 归类，实现协同过滤\n",
    "\n",
    "2. ALS进行矩阵分解的时候，为什么可以并行化处理: ALS 在进行特征内容矩阵分解时只会依赖于自身项，不依赖于其他用户的特征向量，一样可以将不同用户的更新公式放到不同的服务器上执行，因此可以进行并行处理\n",
    "\n",
    "3. 梯度下降法中的批量梯度下降（BGD），随机梯度下降（SGD），和小批量梯度下降有什么区别（MBGD:  批量梯度下降法是最原始的形式，它是指在每一次迭代时使用所有样本来进行梯度的更新.即批量的完成所有梯度下降。 随机梯度下降是每次迭代使用一个样本来对参数进行更新，因此更加快速。 小批量梯度下降，是对批量梯度下降以及随机梯度下降的一个折中，每次迭代使用 batch_size 个样本来对参数进行更新，内存利用率会提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x2abb1ac7f590>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import BaselineOnly, NormalPredictor\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "# import pandas as pd\n",
    "#without titles\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file('./ratings.csv', reader=reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x2abb1ac95150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build_full_trainset()方法可用于在整个训练集上训练\n",
    "train_set = data.build_full_trainset()\n",
    "\n",
    "# ALS优化，用字典的形式表示，n_epoch 是迭代次数，reg_u 是uesr项的正则化系数默认值为15，reg_i 是item 项的正则化系数默认值为10(https://surprise.readthedocs.io/en/stable/prediction_algorithms.html?highlight=reg_u#baselines-estimates-configuration)\n",
    "bsl_options = {'method': 'als','n_epochs': 5,'reg_u': 12,'reg_i': 5}\n",
    "# SGD优化\n",
    "#bsl_options = {'method': 'sgd','n_epochs': 5}\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.8662\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8625\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8632\n",
      "user: 196        item: 302        r_ui = 4.00   est = 4.18   {'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='196', iid='302', r_ui=4, est=4.181439040615394, details={'was_impossible': False})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#algo = BaselineOnly()\n",
    "#基于正太分布预测随机评分 \n",
    "#algo = NormalPredictor()\n",
    "\n",
    "# 定义K折交叉验证迭代器，K=3\n",
    "kf = KFold(n_splits=3)\n",
    "for trainset, testset in kf.split(data):\n",
    "    # 训练并预测\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # 计算RMSE\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "# raw user id (as in the ratings file). They are **strings**!\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "# 输出uid对iid的预测结果\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9544\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9539\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9529\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.72   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='196', iid='302', r_ui=4, est=3.71777688829686, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN \n",
    "from surprise import KNNBasic, NormalPredictor\n",
    "sim_options = {'name': 'cosine','n_epochs': 5,'user_based': True}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "kf = KFold(n_splits=3)\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "曹操使用画地为牢，张飞损失100生命。\n",
      "黄忠 施放 破云之龙 ， 鲁班七号 损失 1 生命 。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 定语从句语法\n",
    "grammar = '''\n",
    "战斗 => 施法  ， 结果 。\n",
    "施法 => 主语 动作 技能 \n",
    "结果 => 主语 获得 效果\n",
    "主语 => 张飞 | 关羽 | 赵云 | 典韦 | 许褚 | 刘备 | 黄忠 | 曹操 | 鲁班七号 | 貂蝉\n",
    "动作 => 施放 | 使用 | 召唤 \n",
    "技能 => 一骑当千 | 单刀赴会 | 青龙偃月 | 刀锋铁骑 | 黑暗潜能 | 画地为牢 | 守护机关 | 狂兽血性 | 龙鸣 | 惊雷之龙 | 破云之龙 | 天翔之龙\n",
    "获得 => 损失 | 获得 \n",
    "效果 => 数值 状态\n",
    "数值 => 1 | 1000 |5000 | 100 \n",
    "状态 => 法力 | 生命\n",
    "'''\n",
    "\n",
    "# 得到语法字典\n",
    "def getGrammarDict(gram, linesplit = \"\\n\", gramsplit = \"=>\"):\n",
    "    result = {}\n",
    "\n",
    "    for line in gram.split(linesplit):\n",
    "\n",
    "        if not line.strip(): \n",
    "            continue\n",
    "        expr, statement = line.split(gramsplit)\n",
    "        result[expr.strip()] = [i.split() for i in statement.split(\"|\")]\n",
    "    #print(result)\n",
    "    return result\n",
    "\n",
    "# 生成句子\n",
    "def generate(gramdict, target, isEng = False):\n",
    "    if target not in gramdict: \n",
    "        return target\n",
    "    find = random.choice(gramdict[target])\n",
    "\n",
    "    blank = ''\n",
    "\n",
    "    if isEng: \n",
    "        blank = ' '\n",
    "    return blank.join(generate(gramdict, t, isEng) for t in find)\n",
    "\n",
    "gramdict = getGrammarDict(grammar)\n",
    "print(generate(gramdict,\"战斗\"))\n",
    "print(generate(gramdict,\"战斗\", True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "黄忠召唤惊雷之龙\n"
     ]
    }
   ],
   "source": [
    "print(generate(gramdict,\"施法\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

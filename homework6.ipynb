{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 在实际工作中，FM和MF哪个应用的更多，为什么: \n",
    "    - FM继承了MF的特征embedding化表达这个优点，同时引入了更多Side information作为特征，将更多特征及Side information embedding化融入FM模型中。所以很明显FM模型更灵活，能适应更多场合的应用范围\n",
    "- FFM与FM有哪些区别？\n",
    "    - FFM 多了一个 Field 概念。理论上FFM 效果不会比Fm 差\n",
    "- DeepFM相比于FM解决了哪些问题，原理是怎样的!\n",
    "    - DeepFM 加多了DNN 网络，从而高阶特征交叉实现组合DNN和FM, 解决了特征组合效果的学习问题。\n",
    "- Surprise工具中的baseline算法原理是怎样的？BaselineOnly和KNNBaseline有什么区别？\n",
    "    -  baseline 是预测给定user item 组合 \n",
    "    -  KNNbaseline 考虑了基础评分的协同过滤算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/guanqzha/kkb_notes\n",
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.4.4\n",
      "  Author:  Steffen Rendle, srendle@libfm.org\n",
      "  WWW:     http://www.libfm.org/\n",
      "This program comes with ABSOLUTELY NO WARRANTY; for details see license.txt.\n",
      "This is free software, and you are welcome to redistribute it under certain\n",
      "conditions; for details see license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "-cache_size     cache size for data storage (only applicable if data is\n",
      "                in binary format), default=infty\n",
      "-dim            'k0,k1,k2': k0=use bias, k1=use 1-way interactions,\n",
      "                k2=dim of 2-way interactions; default=1,1,8\n",
      "-help           this screen\n",
      "-init_stdev     stdev for initialization of 2-way factors; default=0.1\n",
      "-iter           number of iterations; default=100\n",
      "-learn_rate     learn_rate for SGD; default=0.1\n",
      "-load_model     filename for reading the FM model\n",
      "-meta           filename for meta information about data set\n",
      "-method         learning method (SGD, SGDA, ALS, MCMC); default=MCMC\n",
      "-out            filename for output\n",
      "-regular        'r0,r1,r2' for SGD and ALS: r0=bias regularization,\n",
      "                r1=1-way regularization, r2=2-way regularization\n",
      "-relation       BS: filenames for the relations, default=''\n",
      "-rlog           write measurements within iterations to a file;\n",
      "                default=''\n",
      "-save_model     filename for writing the FM model\n",
      "-seed           integer value, default=None\n",
      "-task           r=regression, c=binary classification [MANDATORY]\n",
      "-test           filename for test data [MANDATORY]\n",
      "-train          filename for training data [MANDATORY]\n",
      "-validation     filename for validation data (only for SGDA)\n",
      "-verbosity      how much infos to print; default=0\n"
     ]
    }
   ],
   "source": [
    "#libfm   reference : http://www.libfm.org/libfm-1.42.manual.pdf\n",
    "!pwd\n",
    "!/home/guanqzha/Data/libfm/bin/libFM -help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming file ratings.dat to ratings.dat.libfm...\r\n"
     ]
    }
   ],
   "source": [
    "!/home/guanqzha/Data/libfm/scripts/triple_format_to_libfm.pl -in ratings.dat -target 2 -delete_column 3 -separator \"::\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.4.4\n",
      "  Author:  Steffen Rendle, srendle@libfm.org\n",
      "  WWW:     http://www.libfm.org/\n",
      "This program comes with ABSOLUTELY NO WARRANTY; for details see license.txt.\n",
      "This is free software, and you are welcome to redistribute it under certain\n",
      "conditions; for details see license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 1\n",
      "has xt = 0\n",
      "num_rows=1000209\tnum_values=2000418\tnum_features=9746\tmin_target=1\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 1\n",
      "has xt = 0\n",
      "num_rows=1000209\tnum_values=2000418\tnum_features=9746\tmin_target=1\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "learnrate=0.01\n",
      "learnrates=0.01,0.01,0.01\n",
      "#iterations=100\n",
      "SGD: DON'T FORGET TO SHUFFLE THE ROWS IN TRAINING DATA TO GET THE BEST RESULTS.\n",
      "#Iter=  0\tTrain=0.965124\tTest=0.965124\n",
      "#Iter=  1\tTrain=0.947888\tTest=0.947888\n",
      "#Iter=  2\tTrain=0.93501\tTest=0.93501\n",
      "#Iter=  3\tTrain=0.917388\tTest=0.917388\n",
      "#Iter=  4\tTrain=0.894186\tTest=0.894186\n",
      "#Iter=  5\tTrain=0.872144\tTest=0.872144\n",
      "#Iter=  6\tTrain=0.855061\tTest=0.855061\n",
      "#Iter=  7\tTrain=0.842731\tTest=0.842731\n",
      "#Iter=  8\tTrain=0.833812\tTest=0.833812\n",
      "#Iter=  9\tTrain=0.826934\tTest=0.826934\n",
      "#Iter= 10\tTrain=0.821177\tTest=0.821177\n",
      "#Iter= 11\tTrain=0.816107\tTest=0.816107\n",
      "#Iter= 12\tTrain=0.811597\tTest=0.811597\n",
      "#Iter= 13\tTrain=0.807621\tTest=0.807621\n",
      "#Iter= 14\tTrain=0.804163\tTest=0.804163\n",
      "#Iter= 15\tTrain=0.801191\tTest=0.801191\n",
      "#Iter= 16\tTrain=0.798645\tTest=0.798645\n",
      "#Iter= 17\tTrain=0.796463\tTest=0.796463\n",
      "#Iter= 18\tTrain=0.794583\tTest=0.794583\n",
      "#Iter= 19\tTrain=0.79295\tTest=0.79295\n",
      "#Iter= 20\tTrain=0.79152\tTest=0.79152\n",
      "#Iter= 21\tTrain=0.790255\tTest=0.790255\n",
      "#Iter= 22\tTrain=0.789128\tTest=0.789128\n",
      "#Iter= 23\tTrain=0.788116\tTest=0.788116\n",
      "#Iter= 24\tTrain=0.787204\tTest=0.787204\n",
      "#Iter= 25\tTrain=0.786378\tTest=0.786378\n",
      "#Iter= 26\tTrain=0.785629\tTest=0.785629\n",
      "#Iter= 27\tTrain=0.784948\tTest=0.784948\n",
      "#Iter= 28\tTrain=0.784326\tTest=0.784326\n",
      "#Iter= 29\tTrain=0.783758\tTest=0.783758\n",
      "#Iter= 30\tTrain=0.783238\tTest=0.783238\n",
      "#Iter= 31\tTrain=0.78276\tTest=0.78276\n",
      "#Iter= 32\tTrain=0.782319\tTest=0.782319\n",
      "#Iter= 33\tTrain=0.781909\tTest=0.781909\n",
      "#Iter= 34\tTrain=0.781524\tTest=0.781524\n",
      "#Iter= 35\tTrain=0.78116\tTest=0.78116\n",
      "#Iter= 36\tTrain=0.780813\tTest=0.780813\n",
      "#Iter= 37\tTrain=0.78048\tTest=0.78048\n",
      "#Iter= 38\tTrain=0.78016\tTest=0.78016\n",
      "#Iter= 39\tTrain=0.779851\tTest=0.779851\n",
      "#Iter= 40\tTrain=0.779551\tTest=0.779551\n",
      "#Iter= 41\tTrain=0.77926\tTest=0.77926\n",
      "#Iter= 42\tTrain=0.778979\tTest=0.778979\n",
      "#Iter= 43\tTrain=0.778706\tTest=0.778706\n",
      "#Iter= 44\tTrain=0.778442\tTest=0.778442\n",
      "#Iter= 45\tTrain=0.778188\tTest=0.778188\n",
      "#Iter= 46\tTrain=0.777944\tTest=0.777944\n",
      "#Iter= 47\tTrain=0.77771\tTest=0.77771\n",
      "#Iter= 48\tTrain=0.777488\tTest=0.777488\n",
      "#Iter= 49\tTrain=0.777277\tTest=0.777277\n",
      "#Iter= 50\tTrain=0.777077\tTest=0.777077\n",
      "#Iter= 51\tTrain=0.776888\tTest=0.776888\n",
      "#Iter= 52\tTrain=0.776711\tTest=0.776711\n",
      "#Iter= 53\tTrain=0.776545\tTest=0.776545\n",
      "#Iter= 54\tTrain=0.77639\tTest=0.77639\n",
      "#Iter= 55\tTrain=0.776247\tTest=0.776247\n",
      "#Iter= 56\tTrain=0.776116\tTest=0.776116\n",
      "#Iter= 57\tTrain=0.775996\tTest=0.775996\n",
      "#Iter= 58\tTrain=0.775888\tTest=0.775888\n",
      "#Iter= 59\tTrain=0.775791\tTest=0.775791\n",
      "#Iter= 60\tTrain=0.775706\tTest=0.775706\n",
      "#Iter= 61\tTrain=0.775632\tTest=0.775632\n",
      "#Iter= 62\tTrain=0.77557\tTest=0.77557\n",
      "#Iter= 63\tTrain=0.775519\tTest=0.775519\n",
      "#Iter= 64\tTrain=0.775479\tTest=0.775479\n",
      "#Iter= 65\tTrain=0.77545\tTest=0.77545\n",
      "#Iter= 66\tTrain=0.775431\tTest=0.775431\n",
      "#Iter= 67\tTrain=0.775422\tTest=0.775422\n",
      "#Iter= 68\tTrain=0.775422\tTest=0.775422\n",
      "#Iter= 69\tTrain=0.775432\tTest=0.775432\n",
      "#Iter= 70\tTrain=0.77545\tTest=0.77545\n",
      "#Iter= 71\tTrain=0.775475\tTest=0.775475\n",
      "#Iter= 72\tTrain=0.775507\tTest=0.775507\n",
      "#Iter= 73\tTrain=0.775546\tTest=0.775546\n",
      "#Iter= 74\tTrain=0.77559\tTest=0.77559\n",
      "#Iter= 75\tTrain=0.775639\tTest=0.775639\n",
      "#Iter= 76\tTrain=0.775692\tTest=0.775692\n",
      "#Iter= 77\tTrain=0.775748\tTest=0.775748\n",
      "#Iter= 78\tTrain=0.775807\tTest=0.775807\n",
      "#Iter= 79\tTrain=0.775867\tTest=0.775867\n",
      "#Iter= 80\tTrain=0.775927\tTest=0.775927\n",
      "#Iter= 81\tTrain=0.775987\tTest=0.775987\n",
      "#Iter= 82\tTrain=0.776046\tTest=0.776046\n",
      "#Iter= 83\tTrain=0.776103\tTest=0.776103\n",
      "#Iter= 84\tTrain=0.776159\tTest=0.776159\n",
      "#Iter= 85\tTrain=0.776212\tTest=0.776212\n",
      "#Iter= 86\tTrain=0.776262\tTest=0.776262\n",
      "#Iter= 87\tTrain=0.776309\tTest=0.776309\n",
      "#Iter= 88\tTrain=0.776352\tTest=0.776352\n",
      "#Iter= 89\tTrain=0.776391\tTest=0.776391\n",
      "#Iter= 90\tTrain=0.776426\tTest=0.776426\n",
      "#Iter= 91\tTrain=0.776458\tTest=0.776458\n",
      "#Iter= 92\tTrain=0.776485\tTest=0.776485\n",
      "#Iter= 93\tTrain=0.776507\tTest=0.776507\n",
      "#Iter= 94\tTrain=0.776525\tTest=0.776525\n",
      "#Iter= 95\tTrain=0.776538\tTest=0.776538\n",
      "#Iter= 96\tTrain=0.776546\tTest=0.776546\n",
      "#Iter= 97\tTrain=0.776549\tTest=0.776549\n",
      "#Iter= 98\tTrain=0.776548\tTest=0.776548\n",
      "#Iter= 99\tTrain=0.776541\tTest=0.776541\n",
      "Final\tTrain=0.776541\tTest=0.776541\n"
     ]
    }
   ],
   "source": [
    "#-method sgd\n",
    "!/home/guanqzha/Data/libfm/bin/libFM -task r -train ratings.dat.libfm -test ratings.dat.libfm -method sgd -learn_rate 0.01 -dim '1,1,8' -out ratings.dat.libfm.out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tatanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseFeat(name='movie_id', vocabulary_size=187, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x2ade8ea02b90>, embedding_name='movie_id', group_name='default_group', trainable=True), SparseFeat(name='user_id', vocabulary_size=193, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x2ade452b5610>, embedding_name='user_id', group_name='default_group', trainable=True), SparseFeat(name='gender', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x2ade452b5910>, embedding_name='gender', group_name='default_group', trainable=True), SparseFeat(name='age', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x2ade457894d0>, embedding_name='age', group_name='default_group', trainable=True), SparseFeat(name='occupation', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x2ade45789c90>, embedding_name='occupation', group_name='default_group', trainable=True), SparseFeat(name='zip', vocabulary_size=188, embedding_dim=4, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.RandomNormal object at 0x2ade8ea05cd0>, embedding_name='zip', group_name='default_group', trainable=True)]\n",
      "Train on 128 samples, validate on 32 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guanqzha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/guanqzha/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 4s 33ms/sample - loss: 13.7655 - mse: 13.7655 - val_loss: 14.1950 - val_mse: 14.1950\n",
      "test RMSE 3.883361945531217\n"
     ]
    }
   ],
   "source": [
    "## deepFM\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr.models import DeepFM\n",
    "# from deepctr.inputs import SparseFeat,get_feature_names\n",
    "from deepctr.feature_column import SparseFeat,get_feature_names\n",
    "#数据加载\n",
    "data = pd.read_csv(\"movielens_sample.txt\")\n",
    "sparse_features = [\"movie_id\", \"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "target = ['rating']\n",
    "\n",
    "# 对特征标签进行编码\n",
    "for feature in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feature] = lbe.fit_transform(data[feature])\n",
    "# 计算每个特征中的 不同特征值的个数\n",
    "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique()) for feature in sparse_features]\n",
    "print(fixlen_feature_columns)\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 将数据集切分成训练集和测试集\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}\n",
    "\n",
    "# 使用DeepFM进行训练\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression')\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = model.fit(train_model_input, train[target].values, batch_size=256, epochs=1, verbose=True, validation_split=0.2, )\n",
    "# 使用DeepFM进行预测\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "# 输出RMSE或MSE\n",
    "mse = round(mean_squared_error(test[target].values, pred_ans), 4)\n",
    "rmse = mse ** 0.5\n",
    "print(\"test RMSE\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knnBasic\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import KNNBasic, NormalPredictor\n",
    "# import pandas as pd\n",
    "#without titles\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file('./ratings.csv', reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9560\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9536\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9535\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.74   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='196', iid='302', r_ui=4, est=3.739388263993682, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sim_options = {'name': 'cosine','n_epochs': 5,'user_based': True}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "kf = KFold(n_splits=3)\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8878\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8868\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.8886\n",
      "user: 196        item: 302        r_ui = 4.00   est = 3.96   {'actual_k': 33, 'was_impossible': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='196', iid='302', r_ui=4, est=3.963385119680402, details={'actual_k': 33, 'was_impossible': False})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNWithZScore\n",
    "algo = KNNWithZScore(sim_options=sim_options)\n",
    "kf = KFold(n_splits=3)\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
